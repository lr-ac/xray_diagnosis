{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim    #optim.lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision #torchvision.datasets, torchvision.models, torchvision.transforms\n",
    "import torchvision.transforms as transforms\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau #Reduce learning rate when a metric has stopped improving\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime, os, copy\n",
    "from pathlib import Path\n",
    "from collections import OrderedDict, namedtuple\n",
    "\n",
    "# 'PIL' is the Python Imaging Library, \n",
    "# 'Image' module provides a class to represent a PIL image. \n",
    "## it provides factory functions, like load images from files, and to create new images.\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "#Used to compute Area Under the Receiver Operating Characteristic Curve (ROC AUC) from prediction scores.\n",
    "from sklearn.metrics.ranking import roc_auc_score\n",
    "\n",
    "from sklearn.preprocessing import normalize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3.0\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_raw(path, name):\n",
    "    file = Path(path) / name\n",
    "    if file.exists():\n",
    "        return np.load(file,encoding='bytes')\n",
    "    else:\n",
    "        raise Exception(\"File not found chutia!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_tensor(numpy_array):\n",
    "    # Numpy array -> Tensor\n",
    "    return torch.from_numpy(numpy_array)\n",
    "\n",
    "\n",
    "def to_variable(tensor):\n",
    "    # Tensor -> Variable (on GPU if possible)\n",
    "    if torch.cuda.is_available():\n",
    "        # Tensor -> GPU Tensor\n",
    "        tensor = tensor.cuda()\n",
    "    return torch.autograd.Variable(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#taken from github of arnoweng/CheXNet\n",
    "def compute_AUCs(y_hat, y_true, args):\n",
    "    AUROCs = []\n",
    "    \n",
    "    y_hat = normalize(y_hat, axis=1, norm='l1')\n",
    "    print (y_true.shape)\n",
    "    print (y_hat.shape)\n",
    "    #print (roc_auc_score(y_true, y_hat))\n",
    "    for i in range(args.n_classes):\n",
    "        AUROCs.append(roc_auc_score(y_true[:, i], y_hat[:, i]))\n",
    "        \n",
    "    AUROC_avg = np.array(AUROCs).mean()\n",
    "    print('The average AUROC is {AUROC_avg:.3f}'.format(AUROC_avg=AUROC_avg))\n",
    "    for i in range(args.n_classes):\n",
    "        print('The AUROC of {} is {}'.format(args.disease_categories[i], AUROCs[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DenseNet121(nn.Module):\n",
    "    #!!!def __init__(self, classCount, isTrained):\n",
    "    def __init__(self, args):\n",
    "        #!!!super(DenseNet121, self).__init__()\n",
    "        super().__init__()\n",
    "        self.densenet121 = None\n",
    "        \n",
    "        if args.backprop_pretained:\n",
    "            #Fixed Feature Extractor\n",
    "            #freeze the weights for all of the network except that of the final fully connected layer. \n",
    "            \n",
    "            self.densenet121 = torchvision.models.densenet121(pretrained=True)\n",
    "            for param in self.densenet121.parameters():\n",
    "                param.requires_grad = False\n",
    "            \n",
    "            #parameters = filter(lambda p: p.requires_grad, self.densenet121.parameters())\n",
    "            #for param in parameters:\n",
    "            #    param.requires_grad = False\n",
    "                \n",
    "        else:\n",
    "            #Finetuning \n",
    "            #initialize the network with a pretrained networt. Rest of the training looks as usual.\n",
    "            self.densenet121 = torchvision.models.densenet121(pretrained=True)\n",
    "            \n",
    "        \n",
    "        # Parameters of newly constructed modules have requires_grad=True by default\n",
    "        #fc -> contains the last layer of network (only for resnet)\n",
    "        #classifier -> -> contains the last layer of network (only for densenet)\n",
    "        \n",
    "        ##in RESNET last layer is from 2048 to 1000\n",
    "        #num_features = dcnn.fc.in_features \n",
    "        \n",
    "        ##in DENSENET last layer is from 1024 to 1000\n",
    "        num_features = self.densenet121.classifier.in_features\n",
    "        \n",
    "        self.densenet121.classifier = nn.Sequential(\n",
    "            nn.Linear(num_features, args.n_classes),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        \n",
    "    #each image should be size 224x224 as original paper of Densenet states\n",
    "    def forward(self, input_val):\n",
    "        y = self.densenet121(input_val)\n",
    "        return y\n",
    "    \n",
    "                    \n",
    "    def initialize_weigths(self, args):\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#class ChestXray(torch.utils.data.Dataset):\n",
    "class ChestXray (torch.utils.data.TensorDataset):\n",
    "    def __init__(self, args, dataset_list_file, path, is_val=False):\n",
    "        \n",
    "        \n",
    "        #normalize = transforms.Normalize([12.69, 12.69, 12.69],\n",
    "        #                                 [5.85, 5.85, 5.85])\n",
    "        \n",
    "        normalize = transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                         [0.229, 0.224, 0.225])\n",
    "    \n",
    "        #used in variation of CheXnet of Weng,Zhuang,Tian\n",
    "        self.transform1 = transforms.Compose([\n",
    "                                transforms.Resize(256),\n",
    "                                transforms.TenCrop(224), #return  list of 10 images \n",
    "                                transforms.Lambda (lambda crops: torch.stack([transforms.ToTensor()(x) for x in crops])),\n",
    "                                transforms.Lambda(lambda crops: torch.stack([normalize(x) for x in crops]))\n",
    "                            ])\n",
    "        \n",
    "        #used in original paper of CheXnet of Rajpurkar,Irvin,Zhu,Ng\n",
    "        self.transform2 = transforms.Compose([\n",
    "                                transforms.RandomResizedCrop(224),\n",
    "                                transforms.RandomHorizontalFlip(),\n",
    "                                transforms.ToTensor(),\n",
    "                                normalize\n",
    "                            ])\n",
    "        self.is_val = is_val\n",
    "            \n",
    "        image_names = []\n",
    "        labels = []\n",
    "        tmp = \"all_images\"\n",
    "        #tmp = \"../all_images/images\"\n",
    "        with open(os.path.join(path, dataset_list_file), \"r\") as file:\n",
    "            for line in file:\n",
    "                items = line.split(',')\n",
    "                label = [int(i) for i in items[1:]]\n",
    "                labels.append(label)\n",
    "\n",
    "                image_filename = items[0]\n",
    "                image_name = os.path.join(path,tmp, image_filename)\n",
    "                #image_name = os.path.join(tmp, image_filename)\n",
    "                image_names.append(image_name)\n",
    "                \n",
    "        self.image_names = image_names\n",
    "        self.labels = labels\n",
    "        print (\"There are {} images in the Images Dataset\".format(len(self.image_names)))\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        \n",
    "        image_filename = self.image_names[index]\n",
    "        image = Image.open(image_filename).convert('RGB')\n",
    "        label = torch.FloatTensor(self.labels[index])\n",
    "        if args.transform == \"transform_1\":\n",
    "            if self.is_val == False:\n",
    "                image = self.transform1(image)\n",
    "            else:\n",
    "                image = self.transform2(image)\n",
    "        elif args.transform == \"transform_2\":\n",
    "            image = self.transform2(image)\n",
    "        return image, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_names)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate Routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#routine to compute loss based on Validation dataset\n",
    "def validate_routine(model, args, val_datalist,path):\n",
    "    \n",
    "    model.eval() #DO NOT FORGET to do evaluation\n",
    "    \n",
    "    loss = nn.BCELoss()\n",
    "    \n",
    "    dataset = ChestXray(args, val_datalist, path, is_val=True)\n",
    "    data_loader = torch.utils.data.DataLoader(\n",
    "                    dataset, batch_size=args.batch_size, shuffle=False,\n",
    "                    num_workers=args.num_workers, pin_memory=args.pin_memory)\n",
    "    \n",
    "    losses = []\n",
    "    for i,(input_val,labels) in enumerate(data_loader): \n",
    "            \n",
    "        #forward pass\n",
    "        #print (\"val batch processing: \",i)\n",
    "        prediction = model(to_variable(input_val))\n",
    "\n",
    "        #print(\"Finished forward pass\")\n",
    "        val_loss = loss(prediction, to_variable(labels))\n",
    "        losses.append(val_loss.data.cpu().numpy())\n",
    "            \n",
    "    return losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def training_routine(args, path, train_datalist, val_datalist):\n",
    "    \n",
    "    #open files and load content\n",
    "    \n",
    "    # Create the network\n",
    "    if args.load_disk_model==True:\n",
    "        \n",
    "        \n",
    "        load_model = torch.load(args.load_checkpoint_filename, map_location=lambda storage, loc: storage)\n",
    "        #load_model = torch.load('ChexNet_model2.pytorch')\n",
    "        model = DenseNet121(args)\n",
    "        new_state_dict = OrderedDict()\n",
    "        \n",
    "        tmp = list(model.state_dict().keys())\n",
    "            \n",
    "        for i,(k, v)  in enumerate(load_model.items()):\n",
    "            #print (k)\n",
    "            name = k[7:] # remove `module.`\n",
    "            new_state_dict[tmp[i]] = v\n",
    "        \n",
    "        # load params\n",
    "        model.load_state_dict(new_state_dict)\n",
    "    elif args.load_disk_model == False:\n",
    "        model = DenseNet121(args)  \n",
    "    \n",
    "    #Initialize weitgths\n",
    "    #my_model.initialize_weigths()\n",
    "    \n",
    "    \n",
    "    #Choose the loss function / optimizer\n",
    "    loss = nn.BCELoss(size_average = True)\n",
    "    \n",
    "    #choose optimizer\n",
    "    optim = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()),\n",
    "                            lr=args.learn_rate,\n",
    "                            weight_decay=args.l2)\n",
    "#     optim = torch.optim.SGD(filter(lambda p: p.requires_grad, model.parameters()),\n",
    "#                              lr=args.learn_rate,\n",
    "#                              weight_decay=args.l2,\n",
    "#                              momentum = 0)\n",
    "    scheduler = ReduceLROnPlateau(optim, factor = 0.1, patience = 5, mode = 'min')\n",
    "                         \n",
    "    print (\"Created Neural Network arquitecture\")\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        # Move the network and the optimizer to the GPU\n",
    "        print (\"Moving to GPU\")\n",
    "        model = model.cuda()\n",
    "        model = torch.nn.DataParallel(model).cuda()\n",
    "        loss = loss.cuda()\n",
    "    \n",
    "    dataset = ChestXray(args, train_datalist, path, is_val=False)\n",
    "    \n",
    "    \n",
    "    data_loader = torch.utils.data.DataLoader(\n",
    "                    dataset, batch_size=args.batch_size, shuffle=True,\n",
    "                    num_workers=args.num_workers, pin_memory=args.pin_memory)\n",
    "    \n",
    "    print (\"Created data objects\")\n",
    "    val_losses = []\n",
    "    losses= []\n",
    "    for epoch in range(args.epochs): \n",
    "        model.train()\n",
    "        t0 = datetime.datetime.now()\n",
    "        losses = []\n",
    "        for i,(input_val,labels) in enumerate(data_loader): \n",
    "\n",
    "            #if transform_1 using, we got a vector of 5 DIM\n",
    "            #and we only need a 4 DIM\n",
    "            if args.transform == 'transform_1':  \n",
    "                bs, n_crops, c, h, w = input_val.size() #e.g(4,10,3,224,244)\n",
    "                input_val = input_val.view(-1, c, h, w) #e.g(40,3,224,224)\n",
    "                bs, n_classes = labels.size() #e.g(4,14)\n",
    "                labels = labels.unsqueeze(2).repeat(1, n_crops, 1 )\n",
    "                labels = labels.contiguous().view(bs*n_crops, n_classes)\n",
    "                \n",
    "            prediction = model(to_variable(input_val))\n",
    "\n",
    "            #print(\"Finished forward pass\")\n",
    "            #print (prediction.shape)\n",
    "            \n",
    "            train_loss = loss(prediction, to_variable(labels))\n",
    "            optim.zero_grad()# Reset the gradients NEVER FORGET THIS\n",
    "            train_loss.backward()\n",
    "            optim.step() # Update the network\n",
    "            \n",
    "            losses.append(train_loss.data.cpu().numpy())\n",
    "\n",
    "            \n",
    "            if i % 400 == 0:\n",
    "                print('Minibatch ',i,train_loss.data.cpu().numpy())\n",
    "            #if i % 1200 == 0:\n",
    "                #val_loss = validate_routine(model, args, val_datalist, path)\n",
    "                #scheduler.step(np.asscalar(np.mean(val_loss)))\n",
    "                #model.train()\n",
    "            \n",
    "        val_loss = np.asscalar(np.mean(validate_routine(model, args, val_datalist, path)))   \n",
    "        \n",
    "        val_losses.append(val_loss)\n",
    "        print ('EPOCH', end='\\t')\n",
    "        print (\"Epoch {} Train Loss: {:.4f}\".format(epoch, np.asscalar(np.mean(losses))), end='\\t')\n",
    "        print (\"Epoch {} Validation Loss: {:.4f}\".format(epoch, val_loss), end='\\t')\n",
    "        print (\"Epoch Time: {}\".format(datetime.datetime.now()-t0))\n",
    "        if min(val_losses) == val_loss:\n",
    "            print (\"Saving model on Disk\")\n",
    "            torch.save(model.state_dict(), args.save_checkpoint_filename)\n",
    "        torch.save(model.state_dict(), args.save_checkpoint_filename2)\n",
    "    return model,losses\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "disease_categories = {'Atelectasis': 0, 'Cardiomegaly': 1, 'Effusion': 2,\n",
    "                          'Infiltration': 3, 'Mass': 4, 'Nodule': 5, 'Pneumonia': 6,\n",
    "                          'Pneumothorax': 7, 'Consolidation': 8, 'Edema': 9,\n",
    "                          'Emphysema': 10, 'Fibrosis': 11, 'Pleural_Thickening': 12, 'Hernia': 13,\n",
    "                          }\n",
    "\n",
    "disease_categories2 = {val:key for (key, val) in disease_categories.items()}\n",
    "\n",
    "col_nanes = ['FileName', 'Atelectasis', 'Cardiomegaly', 'Effusion', \n",
    "             'Infiltration', 'Mass', 'Nodule', 'Pneumonia', \n",
    "             'Pneumothorax', 'Consolidation', 'Edema', \n",
    "             'Emphysema', 'Fibrosis', 'Pleural_Thickening', 'Hernia'\n",
    "            ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#in GPU\n",
    "args = {'load_disk_model':True, 'load_checkpoint_filename':'ChexNet_model2.pytorch',\n",
    "        'save_checkpoint_filename':'ChexNet_model4.pytorch',\n",
    "        'save_checkpoint_filename2':'ChexNet_model5.pytorch',\n",
    "        'backprop_pretained':False, #if False do finetuning if True just Fixed Feature Extractor\n",
    "        'n_classes':14, 'transform':'transform_2', 'disease_categories':disease_categories2,\n",
    "        'num_workers':16, 'pin_memory':True, #used for DataLoader\n",
    "        'batch_size':32, 'epochs':2,\n",
    "        'learn_rate':0.00001, 'l2':0.1e-08, #used in optimization \n",
    "       }\n",
    "\n",
    "#in CPU\n",
    "#args['num_workers'] = 16\n",
    "#args['pin_memory'] = True\n",
    "\n",
    "args = namedtuple('args', args.keys())(**args)\n",
    "\n",
    "path = \"dataset\"\n",
    "train = \"train_set.csv\" \n",
    "val = \"val_set.csv\"\n",
    "test = \"test_set.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a = datetime.datetime.now()\n",
    "print (a)\n",
    "print (\"Start Training\")\n",
    "model,losses = training_routine(args, path, train, val)\n",
    "print (\"I am done training\")\n",
    "b = datetime.datetime.now()\n",
    "print (b)\n",
    "print (b-a)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PREDICT TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_from_disk = True\n",
    "if use_from_disk:\n",
    "    load_model = torch.load(args.load_checkpoint_filename, map_location=lambda storage, loc: storage)\n",
    "    #load_model = torch.load('ChexNet_model2.pytorch')\n",
    "    model = DenseNet121(args)\n",
    "    new_state_dict = OrderedDict()\n",
    "    for k, v in load_model.items():\n",
    "        #print (k)\n",
    "        name = k[7:] # remove `module.`\n",
    "        new_state_dict[name] = v\n",
    "    # load params\n",
    "    model.load_state_dict(new_state_dict)\n",
    "    #model.load_state_dict(load_model)\n",
    "    if torch.cuda.is_available():\n",
    "        # Move the network and the optimizer to the GPU\n",
    "        print (\"Moving to GPU\")\n",
    "        model = model.cuda()\n",
    "        model = torch.nn.DataParallel(model).cuda()\n",
    "    #print(model) \n",
    "\n",
    "\n",
    "t0 = datetime.datetime.now()\n",
    "\n",
    "model.eval() #DO NOT FORGET to do evaluation\n",
    "\n",
    "\n",
    "dataset = ChestXray(args, test, path, is_val=True)\n",
    "data_loader = torch.utils.data.DataLoader(\n",
    "                dataset, batch_size=args.batch_size, shuffle=False,\n",
    "                num_workers=args.num_workers, pin_memory=args.pin_memory)\n",
    "\n",
    "\n",
    "y_hat = []\n",
    "y_true = []\n",
    "for i,(input_val,labels) in enumerate(data_loader): \n",
    "\n",
    "    #forward pass\n",
    "    if i % 50 == 0:\n",
    "        print (\"val batch processing: \",i)\n",
    "                \n",
    "    prediction = model(to_variable(input_val))\n",
    "    #print (\"Donde Forward Pass\")\n",
    "    y_true.append(labels.cpu().numpy().astype(int))\n",
    "    y_hat.append(prediction.data.cpu().numpy())\n",
    "    \n",
    "\n",
    "y_hat = np.vstack(y_hat)\n",
    "y_true = np.vstack(y_true)\n",
    "compute_AUCs(y_hat, y_true, args)\n",
    "print (\"Predict Time: {}\".format(datetime.datetime.now()-t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HEATMAP GENERATOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "image = Image.open(\"dataset/all_images/00000001_002.png\").convert('RGB')\n",
    "args['batch_size'] = 1\n",
    "\n",
    "weights = list(model.parameters())[-2]\n",
    "print (weights.shape)\n",
    "\n",
    "\n",
    "\n",
    "heatmap = None\n",
    "for i in range (weights.shape[0]):\n",
    "    map = output[0,i,:,:]\n",
    "    if i == 0: heatmap = self.weights[i] * map\n",
    "    else: heatmap += self.weights[i] * map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([14, 1024])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
